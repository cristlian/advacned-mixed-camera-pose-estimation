# Advanced Mixed-Camera 3D Pose Estimation (Offline Pipeline)

## ğŸ“Œ Project Scope
This project implements an **offline multi-camera 3D pose estimation pipeline** designed to process pre-recorded video footage. The system utilizes a mixed-camera setup consisting of **one fisheye camera and two standard rectilinear cameras**.

The primary goal is to demonstrate robust backend engineering, computer vision, and machine learning engineering (MLE) skills by prioritizing accuracy and architectural cleanliness over real-time performance.

## ğŸ“‚ Module Status

| Module | Status | Description |
| :--- | :--- | :--- |
| `main.py` | âœ… Active | Pipeline orchestrator and entry point. |
| `calibration_loader.py` | âœ… Active | Manages camera intrinsics and extrinsics loading. |
| `capture.py` | âœ… Active | Handles synchronized frame ingestion from video files. |
| `detection.py` | âœ… Active | Performs 2D pose estimation using YOLOv8. |
| `triangulation.py` | âœ… Active | Reconstructs 3D points from multi-view 2D detections. |
| `filtering.py` | âœ… Active | Applies temporal filtering (OneEuro/Kalman) for smoothing. |
| `tools/visualize_3d_output.py` | âœ… Active | Generates 3D visualizations of the output data. |
| `streaming.py` | â¸ï¸ Inactive | Real-time WebSocket server (Moved to Future Work). |

## ğŸ“š Documentation

Detailed documentation for the system architecture and specific strategies can be found in the `docs/` directory:

- [**System Architecture**](docs/architecture.md): Overview of the data flow and pipeline stages.
- [**Fisheye Integration Strategy**](docs/fisheye_strategy.md): Details on how the mixed-camera setup and fisheye distortion are handled.

## âš™ï¸ Setup & Usage

### Prerequisites
- Python 3.10+
- Conda (recommended)

### Environment Setup

1.  **Create the environment:**
    ```bash
    conda env create -f environment.yml
    conda activate vision3d
    ```

2.  **Install dependencies (if not using environment.yml):**
    ```bash
    pip install -r requirements.txt
    pip install -r requirements-dev.txt  # For development tools
    ```

### Running the Pipeline

To run the full pipeline on a set of recorded videos:

```bash
python main.py --config config.toml --output results/
```

*(Note: Ensure your `config.toml` points to the correct video paths and calibration files.)*

## ğŸ”® Future Work / Long-Term Roadmap

The following features are part of the long-term vision but are currently out of scope for the offline pipeline:

- **Real-Time Processing**: Optimizing the pipeline for live streaming and low-latency inference.
- **Live Streaming**: Re-enabling `streaming.py` to serve pose data to WebSocket clients.
- **Advanced Fisheye Models**: Training custom pose estimation models specifically for fisheye distortion.
- **Dynamic Calibration**: Implementing runtime calibration refinement.
